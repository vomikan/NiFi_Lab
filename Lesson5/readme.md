# Lesson 5: Замена данных с использованием справочников в Apache NiFi

В данной статье представлены два пайплайна, которые демонстрируют различные подходы к работе со справочниками и замене данных в Apache NiFi.

## Пайплайн 1: Заполнение справочников данными
Этот пайплайн отвечает за заполнение справочников [данными](https://raw.githubusercontent.com/sorokinpf/russian_names/refs/heads/master/russian_surnames.txt), которые будут использоваться для замены значений в основном потоке данных. Справочники будут загружены в CSV, SQL и Redis.
Файл для SQLite необходимо заранее подготовить и расположить в доступном для NiFi каталоге. Удобно использовать утилиту [DB Browser for SQLite](https://sqlitebrowser.org/)

```sql
CREATE TABLE "russian_surnames" (
	"id"	INTEGER,
	"surname"	TEXT NOT NULL,
	PRIMARY KEY("id" AUTOINCREMENT)
);
```
Путь к файлу БД в дальнейшем надо указать в сервисе DBCPConnectionPool.

Для Postrgesql аналогичным образом надо создать таблицу
```sql
create table russian_surnames
(
	id bigserial not null
		constraint russian_surnames_pkey
			primary key,
	surname text not null
);
```

Визуализация
Ниже представлена схема flow который производит обработку входящих записей и меняет в них фамилии на те, которые есть в справочнике:

![NiFi Flow](pipeline.png)

## Пайплайн 2: Замена фамилий с использованием справочников
Второй пайплайн выполняет замену фамилий в данных на случайные фамилии из справочников. Задача решается пятью различными способами с использованием следующих процессоров:

1. **LookupRecord (CSV)** – замена данных с использованием справочника в формате CSV.
2. **LookupRecord (SQL)** – замена данных с использованием SQL-запросов к базе данных.
3. **LookupRecord (Redis)** – замена данных с использованием Redis в качестве хранилища справочников.
4. **LookupRecord (SQL PG)** – замена данных с использованием PostgreSQL в качестве источника справочников.
5. **ExecuteGroovyScript (Redis)** – замена данных с использованием Groovy-скрипта для работы с Redis.

## Требования для урока
Для выполнения данного урока требуется отдельно установленные Redis и PostgreSQL. Это необходимо для работы с соответствующими процессорами и проведения сравнительного анализа.

## Сравнительный анализ производительности
Все пять методов работают параллельно, что позволяет визуально сравнить их производительность. Очевидно, что `LookupRecord` в Redis и PostgreSQL значительно уступают по скорости обработки данных. Предполагается, что это связано с большим количеством сетевых транзакций.

### Проверка гипотезы
Для проверки гипотезы о влиянии сетевых транзакций на производительность, можно проанализировать логи PostgreSQL.

#### Включение подробного лога PostgreSQL (если PostgreSQL запущен в Docker)
1. Подключитесь к контейнеру с PostgreSQL:
```bash
   docker exec -it <container_id> bash
```
Откройте конфигурационный файл PostgreSQL:

```
nano /var/lib/postgresql/data/pgdata/postgresql.conf
```
Найдите и измените следующие параметры:

```
log_statement = 'all'
log_duration = on
```
Перезапустите PostgreSQL:

```
service postgresql restart
```
Просмотр лога
Для просмотра лога в реальном времени используйте команду:

```
tail -f /var/lib/postgresql/data/pgdata/log/postgresql-<YYYY-MM-DD_XXXXXX>.log
```
Пример лога
```
BEGIN
22:28:11.031 UTC [15977] LOG:  execute <unnamed>/C_9: SELECT * FROM russian_surnames
22:28:11.038 UTC [15977] LOG:  execute fetch from <unnamed>/C_9: SELECT * FROM russian_surnames
22:28:11.044 UTC [15977] LOG:  execute fetch from <unnamed>/C_9: SELECT * FROM russian_surnames
22:28:11.050 UTC [15977] LOG:  execute fetch from <unnamed>/C_9: SELECT * FROM russian_surnames
.....
22:28:11.621 UTC [15977] LOG:  execute S_2: COMMIT
```
Из лога видно, что происходит запрос для каждого ключа отдельно, что может быть причиной снижения производительности.

### Анализ производительности Groovy-скрипта

Обратите внимание на код, написанный на Groovy. Данный алгоритм делает запрос в Redis методом `MGET`, который позволяет за одну транзакцию получить ответ по набору ключей и затем объединить (смержить) результат. Такой подход обеспечивает ощутимый прирост производительности по сравнению с последовательными запросами.

Пример работы метода `MGET`:
- Вместо множества отдельных запросов к Redis, Groovy-скрипт отправляет один запрос с несколькими ключами.
- Redis возвращает все значения за одну операцию, что значительно сокращает количество сетевых транзакций и время обработки.

### Выводы

1. **Процессор LookupRecord использует неоптимальные методы**:
   - При работе с Redis и PostgreSQL процессор выполняет множество отдельных запросов, что приводит к увеличению сетевых транзакций и снижению производительности.
   - В отличие от Groovy-скрипта, который использует метод `MGET`, LookupRecord не оптимизирован для массовой обработки данных.

2. **Lookup на базе CSV работает отлично**:
   - Несмотря на отсутствие индексов (в отличие от SQLite), процессор LookupRecord с CSV демонстрирует высокую производительность.
   - Это связано с тем, что данные хранятся локально, и отсутствуют накладные расходы на сетевые запросы.

Таким образом, для задач, требующих высокой производительности, рекомендуется использовать оптимизированные подходы, такие как Groovy-скрипты или свой кастомный процессор. 


Данный материал будет полезен для разработчиков, которые хотят изучить различные методы работы со справочниками и замены данных в Apache NiFi, а также провести сравнительный анализ производительности разных подходов.
