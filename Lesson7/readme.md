## Урок 7: Фильтрация содержимого записи
В этом уроке мы рассмотрим, как фильтровать данные в JSON, при условии что данные не являются "плоскими". 
Мы используем несколько процессоров для выполнения этой задачи и сравним их производительность.

### Описание flow
На входе формируется JSON файл. Это некий профиль с массивом адресов.
Задача состоит с вом, чтобы оставить только адреса с типами 11 и 15.
Пример данных:
```json
{
  "profile": {
    "addresses": [
      {
        "id": "original-da11-11eb-beb6-87ba01ce01e0",
        "type": "13",
        "begin_date": "2020-01-01 00:00:00.000",
        "full_address": "ул. Петра Первого, 13, кв. 81.....",
        "last_update_dt": "2016-11-15",
		"del_sign": false
      },
      {
        "id": "original-da11-11eb-beb6-87ba01ce01e0",
        "type": "11",
        "begin_date": "2020-01-01 00:00:00.000",
        "full_address": "наб. Обводного канала оф. 81.....",
        "last_update_dt": "2024-12-16",
		"del_sign": false
      }
    ],
    "birth_dt": "2000-01-01 00:00:00.000",
    "cards": [],
    "contacts": [],
    "del_sign": false,
    "documents": [],
    "spec_type": 0
  }
}
```

2. Процессоры для фильтрации
Мы рассмотрим несколько подходов для фильтрации данных:

a) JSLTTransformJSON

Скрипт:
```javascript
let filtered_addresses = 
  [for (.profile.addresses) .
    if (contains(.type, ["11", "15"]) and .del_sign == false)
  ]
{
  "profile" : {
    "addresses": $filtered_addresses,
    * : .
  }
}

```

b) JoltTransformJSON
Спецификация:
```json
[
  {
    "operation": "shift",
    "spec": {
      "profile": {
        "addresses": {
          "*": {
            "del_sign": {
              "false": {
                "@2": "&5.&4[]"
              }
            }
          }
        },
        "*": "&1.&"
      }
    }
  },
  {
    "operation": "shift",
    "spec": {
      "profile": {
        "addresses": {
          "*": {
            "type": {
              "11|15": {
                "@2": "&5.&4[]"
              }
            }
          }
        },
        "*": "&1.&"
      }
    }
  }
]

```

e) ExecuteStreamCommand c grep


### Как использовать
Импорт flow:
Загрузите файл Lesson7.json из репозитория.
Импортируйте его в NiFi через контекстное меню (Drag & Drop или через меню создания группы).

Активация сервисов:
Включите все контроллеры через контекстное меню Enable All Controller Services.

Запуск потока:
Запустите процессор GenerateRecord для генерации тестовых данных.

Наблюдайте за работой процессоров и сравните их производительность.

Анализ результатов:
Остановите поток через контекстное меню Stop.

Удалите файлы через контекстное меню канваса Empty All Queues.

Визуализация
Ниже представлена схема flow:

![NiFi Flow](pipeline.png)

Выводы
Производительность:
У данных процессоров практически одинаковая скорость обработки данных.

Гибкость:

ExecuteGroovyScript и ScriptedTransformRecord предоставляют больше гибкости для сложной логики фильтрации.
Такие скрипты легко можно создать с нуля с использованием ИИ.
Процессоры JSLTTransformJSON и JoltTransformJSON потребуют изучения сложных спецификаций JSLT и JOLT соответвенно.4
Это осложняется тем, что нет хорошо обученных моделей ИИ для этого. Как правило, вы получите глюк. 

Этот урок демонстрирует, как можно решать одну и ту же задачу разными способами в NiFi, и помогает понять, какой подход лучше подходит для конкретных сценариев.
